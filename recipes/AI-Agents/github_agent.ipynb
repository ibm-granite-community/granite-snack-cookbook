{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "introduction"
      },
      "source": [
        "# Building a GitHub Agent with LangGraph and LangChain\n",
        "\n",
        "This notebook guides you through building an intelligent agent that can interact with GitHub repositories. Using LangGraph, LangChain, and IBM's Granite LLM, you'll create an agent capable of performing various GitHub operations through natural language instructions.\n",
        "\n",
        "## What You'll Learn\n",
        "- How to set up API connections to GitHub\n",
        "- How to serve and interact with an LLM (IBM Granite)\n",
        "- How to create tools that interact with GitHub's API\n",
        "- How to build a ReAct agent that can reason about GitHub tasks\n",
        "\n",
        "## Prerequisites\n",
        "- GitHub account with a repository you want the agent to access\n",
        "- Either a local Ollama server or a Replicate API token\n",
        "- Basic understanding of Python and LLMs\n",
        "\n",
        "Let's start by insuring we are using Python 3.10 or 3.11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8o9Ga6mBAus"
      },
      "outputs": [],
      "source": [
        "\n",
        "import sys\n",
        "assert sys.version_info >= (3, 10) and sys.version_info <= (3, 12), \"Use Python 3.10, 3.11 or 3.12 to run this notebook.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4C5FZicBAut"
      },
      "source": [
        "and Installing some dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wHsVa-PXBhfz"
      },
      "outputs": [],
      "source": [
        "! pip install langgraph\n",
        "! pip install --upgrade --quiet pygithub langchain-community replicate\n",
        "! pip install git+https://github.com/ibm-granite-community/utils \\\n",
        "  langchain_ollama\n",
        "! pip install python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connecting to GitHub\n",
        "\n",
        "For your agent to interact with GitHub, it needs proper authentication. We'll use GitHub Apps for this purpose, which provides a secure way to access repositories.\n",
        "\n",
        "### Setting Up Your GitHub App\n",
        "\n",
        "1. Follow the instructions [here](https://docs.github.com/en/apps/creating-github-apps/registering-a-github-app/registering-a-github-app) to create a GitHub App\n",
        "2. Configure the following permissions for your app:\n",
        "   - Repository contents: Read & Write\n",
        "   - Issues: Read & Write\n",
        "   - Pull requests: Read & Write\n",
        "3. Generate a private key for your app\n",
        "4. Install the app to your repository\n",
        "\n",
        "After setting up your GitHub App, you'll need three pieces of information:\n",
        "- Your repository name in the format `username/repo-name`\n",
        "- The private key file (downloaded when you created the app). You will need to upload the key to your local filestore and input the path to the key file.\n",
        "- The GitHub App ID (found in your app's settings)\n",
        "\n",
        "Let's set these as environment variables:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zzffpEQES1x"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "This notebook supports two ways to set up your environment variables:\n",
        "\n",
        "1. Using a `.env` file (recommended)\n",
        "2. Setting environment variables manually\n",
        "\n",
        "### Option 1: Using a .env File\n",
        "\n",
        "Create a `.env` file in the same directory as this notebook with the following variables:\n",
        "\n",
        "```\n",
        "# GitHub credentials\n",
        "GITHUB_REPOSITORY=your/githubrepo\n",
        "GITHUB_APP_PRIVATE_KEY=your/private_key.pem\n",
        "GITHUB_APP_ID=your_github_app_id\n",
        "\n",
        "# LLM credentials (if using Replicate)\n",
        "REPLICATE_API_TOKEN=your_replicate_api_token\n",
        "\n",
        "# Optional: Ollama host (if not using default)\n",
        "# OLLAMA_HOST=http://127.0.0.1:11434\n",
        "```\n",
        "\n",
        "Let's load the environment variables from the `.env` file if it exists:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i98Y-e4dEWaH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from ibm_granite_community.notebook_utils import get_env_var\n",
        "\n",
        "# Try to load from .env file if it exists\n",
        "env_file = '/your/file.env' #Replace with your .env file path\n",
        "if os.path.exists(env_file):\n",
        "    print(f\"Loading environment variables from {env_file}\")\n",
        "    load_dotenv(env_file)\n",
        "else:\n",
        "    print(\".env file not found. You'll need to set environment variables manually.\")\n",
        "\n",
        "# Display status of GitHub configuration\n",
        "print(\"\\nGitHub Configuration Status:\")\n",
        "print(f\"  Repository: {'Set' if get_env_var('GITHUB_REPOSITORY') else 'Not set'}\")\n",
        "print(f\"  App ID: {'Set' if get_env_var('GITHUB_APP_ID') else 'Not set'}\")\n",
        "print(f\"  Private Key: {'Set' if get_env_var('GITHUB_APP_PRIVATE_KEY') else 'Not set'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTqugmeKFjde"
      },
      "source": [
        "### Option 2: Manual Environment Setup\n",
        "\n",
        "If you didn't set up a `.env` file or need to override some variables, you can set them directly here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qq5fVJMFhSA"
      },
      "outputs": [],
      "source": [
        "# Only run this cell if you need to manually set or override environment variables\n",
        "# If you're using a .env file and all variables are correctly set, you can skip this cell\n",
        "\n",
        "# Uncomment and set any missing variables\n",
        "# os.environ[\"GITHUB_REPOSITORY\"] = \"your/githubrepo\"\n",
        "# os.environ[\"GITHUB_APP_ID\"] = \"your_github_app_id\"\n",
        "# os.environ[\"GITHUB_APP_PRIVATE_KEY\"] = \"your/private_key.pem\"\n",
        "\n",
        "# Or set the key content directly (not recommended for security reasons):\n",
        "# os.environ[\"GITHUB_APP_PRIVATE_KEY\"] = \"\"\"-----BEGIN RSA PRIVATE KEY-----\n",
        "# ...\n",
        "# -----END RSA PRIVATE KEY-----\"\"\"\n",
        "\n",
        "# For Replicate (if you're not using Ollama):\n",
        "# os.environ[\"REPLICATE_API_TOKEN\"] = \"your_replicate_api_token\"\n",
        "\n",
        "# Verify the required variables are set\n",
        "required_vars = [\"GITHUB_REPOSITORY\", \"GITHUB_APP_ID\", \"GITHUB_APP_PRIVATE_KEY\"]\n",
        "missing_vars = [var for var in required_vars if not get_env_var(var)]\n",
        "\n",
        "if missing_vars:\n",
        "    print(f\"Warning: The following required variables are still not set: {', '.join(missing_vars)}\")\n",
        "    print(\"Please set them before proceeding.\")\n",
        "else:\n",
        "    print(\"All required GitHub variables are set.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tlp8yuQBAut"
      },
      "source": [
        "## Setting Up the LLM\n",
        "\n",
        "Our agent needs an LLM to generate responses and make decisions. We'll use IBM's Granite model, which can be served in two ways:\n",
        "\n",
        "1. **Local deployment via Ollama**: Faster and free, but requires local resources\n",
        "2. **Cloud deployment via Replicate**: Accessible from anywhere, but requires an API token\n",
        "\n",
        "The code below will try to use a local Ollama server first, and if that's not available, it will fall back to Replicate.\n",
        "\n",
        "### Setting Up Ollama (Optional)\n",
        "If you want to use Ollama:\n",
        "1. Install Ollama from [https://ollama.ai/](https://ollama.ai/)\n",
        "2. Run `ollama pull granite3.2:8b` to download the model\n",
        "\n",
        "### Setting Up Replicate\n",
        "If you want to use Replicate:\n",
        "1. Create an account at [https://replicate.com/](https://replicate.com/)\n",
        "2. Generate an API token at [https://replicate.com/account/api-tokens](https://replicate.com/account/api-tokens)\n",
        "\n",
        "Let's set up our LLM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwOeYK5Hdm6q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "from langchain_community.llms import Replicate\n",
        "from ibm_granite_community.notebook_utils import get_env_var\n",
        "\n",
        "try: # Look for a locally accessible Ollama server for the model\n",
        "    response = requests.get(os.getenv(\"OLLAMA_HOST\", \"http://127.0.0.1:11434\"))\n",
        "    llm = OllamaLLM(\n",
        "        model=\"granite3.2:8b\",\n",
        "        num_ctx=65536, # 64K context window\n",
        "    )\n",
        "# Initialize Replicate\n",
        "except Exception:\n",
        "  llm = Replicate(\n",
        "    model =\"ibm-granite/granite-3.2-8b-instruct\",\n",
        "      #Be sure to have your 'REPLICATE_API_TOKEN' set from previous steps\n",
        "      replicate_api_token = get_env_var('REPLICATE_API_TOKEN'),\n",
        "      model_kwargs={\n",
        "          \"max_tokens\": 2000, # Set the maximum number of tokens to generate as output.\n",
        "          \"min_tokens\": 200, # Set the minimum number of tokens to generate as output.\n",
        "          \"temperature\": 0.75,\n",
        "          \"presence_penalty\": 0,\n",
        "          \"frequency_penalty\": 0,\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0raS-PQdBAuu"
      },
      "source": [
        "## Testing the LLM\n",
        "\n",
        "Before building our agent, it's a good idea to test the LLM to make sure it's working properly. This simple test ensures that we can connect to either Ollama or Replicate and that the model responds as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_llm_cell"
      },
      "outputs": [],
      "source": [
        "# Test the LLM to make sure it's working\n",
        "llm.invoke(\"Hello, what can you help me with today?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOH9cERwBAuu"
      },
      "source": [
        "## Creating the GitHub Toolkit\n",
        "\n",
        "Now that we have our GitHub credentials and LLM set up, let's create the GitHub toolkit. This toolkit provides a set of tools that our agent can use to interact with GitHub.\n",
        "\n",
        "LangChain provides a convenient `GitHubToolkit` class that wraps around the GitHub API. Let's initialize it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6xj5d9L4LoQ"
      },
      "outputs": [],
      "source": [
        "from langchain_community.agent_toolkits.github.toolkit import GitHubToolkit\n",
        "from langchain_community.utilities.github import GitHubAPIWrapper\n",
        "\n",
        "github = GitHubAPIWrapper()\n",
        "toolkit = GitHubToolkit.from_github_api_wrapper(github)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnetCLVBBAuu"
      },
      "source": [
        "## Exploring Available GitHub Tools\n",
        "\n",
        "Let's explore the tools that are available in our GitHub toolkit. Each tool represents a specific action our agent can take on GitHub, such as creating an issue, commenting on a pull request, or reading file contents.\n",
        "\n",
        "This step helps us understand what our agent is capable of doing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHkCEGi9-I5M"
      },
      "outputs": [],
      "source": [
        "tools = toolkit.get_tools()\n",
        "print(\"Available tools:\")\n",
        "for tool in tools:\n",
        "    print(f\"- {tool.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcEKXcsfBAuu"
      },
      "source": [
        "## Building the ReAct Agent\n",
        "\n",
        "Now we're ready to build our GitHub agent! We'll use the ReAct (Reasoning and Acting) framework, which allows our agent to:\n",
        "\n",
        "1. Think about what it should do (Reasoning)\n",
        "2. Take an action using one of the GitHub tools (Acting)\n",
        "3. Observe the result of that action\n",
        "4. Reason about what to do next based on those observations\n",
        "\n",
        "This approach allows the agent to break down complex GitHub tasks into a series of steps.\n",
        "\n",
        "We'll start by defining a prompt template that instructs the LLM on how to use the ReAct framework:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhTtEHeNAtxa"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"You are a helpful GitHub assistant who can perform various actions on GitHub repositories.\n",
        "You have access to the following tools:\n",
        "\n",
        "{tools}\n",
        "\n",
        "Use the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about what to do\n",
        "Action: the action to take, must be one of [{tool_names}]\n",
        "Action Input: input passed to tool\n",
        "Observation: action result\n",
        "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Begin!\n",
        "\n",
        "Question: {input}\n",
        "Thought: {agent_scratchpad}\n",
        "\"\"\"\n",
        "\n",
        "# Create the prompt template\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"input\", \"agent_scratchpad\"],\n",
        "    partial_variables={\n",
        "        \"tools\": lambda x: format_tool_string(tools),\n",
        "        \"tool_names\": lambda x: \", \".join([tool.name for tool in tools]),\n",
        "    },\n",
        ")\n",
        "\n",
        "# Helper function to format tools\n",
        "def format_tool_string(tools):\n",
        "    return \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])\n",
        "\n",
        "# Create a memory to maintain conversation context\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Instantiate the ReAct agent using LangChain's create_react_agent\n",
        "agent = create_react_agent(\n",
        "    llm,\n",
        "    tools,\n",
        "    prompt,\n",
        ")\n",
        "\n",
        "# Create an agent executor with the ReAct agent\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    memory=memory,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibQvt_yzBAuv"
      },
      "source": [
        "## Creating a Helper Function to Run the Agent\n",
        "\n",
        "Now that our agent is set up, let's create a helper function that makes it easy to run the agent with different queries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjbm-dtjGl1U"
      },
      "outputs": [],
      "source": [
        "def run_github_agent(query):\n",
        "    \"\"\"Run the GitHub agent with a user query.\"\"\"\n",
        "    result = agent_executor.invoke({\"input\": query})\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1avL4KJmBAuv"
      },
      "source": [
        "## Testing the GitHub Agent\n",
        "\n",
        "Now that our agent is fully set up, let's test it with a simple query. This example asks the agent to count the number of issues in the repository:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAFJHz8FDnhK"
      },
      "outputs": [],
      "source": [
        "result = run_github_agent(\"how many issues are there\")\n",
        "print(result[\"output\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHUQ_3TzBAuv"
      },
      "source": [
        "## Example Use Cases\n",
        "\n",
        "Here are some example queries you can try with your GitHub agent:\n",
        "\n",
        "```python\n",
        "# Get information about repositories\n",
        "run_github_agent(\"List all the files in the repository\")\n",
        "run_github_agent(\"What are the most recent commits?\")\n",
        "\n",
        "# Work with issues\n",
        "run_github_agent(\"Create a new issue titled 'Update documentation' with description 'We need to update the README file'\")\n",
        "run_github_agent(\"List all open issues\")\n",
        "run_github_agent(\"Close issue #1\")\n",
        "\n",
        "# Work with pull requests\n",
        "run_github_agent(\"List all open pull requests\")\n",
        "run_github_agent(\"Comment on pull request #2 saying 'Looks good, approved!'\")\n",
        "\n",
        "# Work with file contents\n",
        "run_github_agent(\"What's in the README.md file?\")\n",
        "run_github_agent(\"Create a new file called 'hello.txt' with content 'Hello, world!'\")\n",
        "```\n",
        "\n",
        "Feel free to experiment with different queries based on your repository's contents and what you want to accomplish!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgpb0VV5BAuv"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Congratulations! You've built a functional GitHub agent that can interact with your repository using natural language instructions. This agent demonstrates the power of combining LLMs with API tools to create useful AI assistants.\n",
        "\n",
        "### What You've Learned\n",
        "- How to set up GitHub App authentication\n",
        "- How to connect to and utilize an LLM (IBM Granite)\n",
        "- How to create a ReAct agent that can reason about and execute GitHub operations\n",
        "- How to use LangChain and LangGraph to create an AI agent with tool-using capabilities\n",
        "\n",
        "### Next Steps\n",
        "- Try more complex queries and see how the agent handles them\n",
        "- Add more specialized tools for specific GitHub operations\n",
        "- Integrate this agent with other services like Slack or Discord\n",
        "- Refine the agent's prompt to make it better at specific tasks"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
