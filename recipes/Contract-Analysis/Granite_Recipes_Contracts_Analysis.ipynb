{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contract Analysis using IBM Granite LLM from watsonx\n",
    "Author: [@Aisha Mohammed Farooq Darga](https://www.linkedin.com/in/aisha-mohammed-farooq-darga-778280135/)\n",
    "\n",
    "## **Description**\n",
    "\n",
    "Contract analysis involves reviewing, interpreting, and extracting key information from contract documents to identify risks, obligations, and critical aspects. This ensures clarity on terms and conditions, helps avoid ambiguities, and mitigates potential legal or financial complications. \n",
    "\n",
    "Effective contract analysis is crucial for businesses, legal professionals, and stakeholders, as it safeguards against unintentional obligations, disputes, and risks.\n",
    "\n",
    "---\n",
    "\n",
    "## **What Does This Notebook Do?**\n",
    "\n",
    "This notebook provides an **automated solution** for contract analysis using **IBM Granite LLM** from watsonx. By leveraging advanced language models and **ChromaDB**, the notebook accomplishes the following:\n",
    "\n",
    "- Offers a **general overview** of the contract.\n",
    "- Extracts and highlights **key terms**, such as payment terms, intellectual property rights, termination clauses, and dispute resolution methods.\n",
    "- Conducts **detailed risk analysis** to uncover and assess potential issues.\n",
    "- Provides **recommendations and actionable insights** for risk mitigation.\n",
    "- Compiles a **compliance checklist** and a **risk summary table** categorized by severity.\n",
    "\n",
    "---\n",
    "\n",
    "## **Approach Followed**\n",
    "\n",
    "The notebook uses a systematic multi-step approach:\n",
    "\n",
    "1. **Text Extraction and Chunking**: \n",
    "   - Reads the contract and divides it into manageable chunks for efficient processing.\n",
    "2. **Embedding the Text**:\n",
    "   - Converts text chunks into embeddings using the **Granite LLM** model for semantic representation.\n",
    "3. **Storing in ChromaDB**:\n",
    "   - Stores the embeddings in **ChromaDB**, enabling efficient retrieval of context-specific sections.\n",
    "4. **Proximity Search**:\n",
    "   - Retrieves relevant sections based on queries using embedding-based proximity search.\n",
    "5. **AI-Driven Risk Assessment**:\n",
    "   - Analyzes retrieved content to generate a structured evaluation of key terms, risks, and recommendations.\n",
    "\n",
    "---\n",
    "\n",
    "## **Output Details**\n",
    "\n",
    "The notebook produces the following outputs:\n",
    "\n",
    "1. **General Overview**:\n",
    "   - Summarizes effective date, involved parties, and scope of work.\n",
    "\n",
    "2. **Key Highlights**:\n",
    "   - Outlines major clauses: payment terms, intellectual property rights, termination provisions, and dispute resolution methods.\n",
    "\n",
    "3. **Detailed Risk Analysis**:\n",
    "   - Identifies potential risks, categorizes their severity (Low, Medium, High), and suggests mitigation strategies.\n",
    "\n",
    "4. **Recommendations and Insights**:\n",
    "   - Provides actionable recommendations for contract improvement.\n",
    "\n",
    "5. **Compliance Checklist**:\n",
    "   - Lists unaddressed risks and compliance issues.\n",
    "\n",
    "6. **Summary of Risks by Severity**:\n",
    "   - Creates a structured table summarizing risks, severity, and mitigation strategies.\n",
    "\n",
    "---\n",
    "\n",
    "## **Prerequisites**\n",
    "\n",
    "- **IBM Cloud Account**: [Sign up here](https://cloud.ibm.com/registration).\n",
    "- **Python Version**: Ensure Python 3.11.9 is installed.\n",
    "\n",
    "---\n",
    "\n",
    "## **Environment Setup**\n",
    "\n",
    "### 1. **IBM Cloud Account Setup**\n",
    "- Log in to [watsonx.ai](https://dataplatform.cloud.ibm.com/registration/stepone?context=wx&apps=all).\n",
    "- Create a [watsonx.ai Project](https://www.ibm.com/docs/en/watsonx/saas?topic=projects-creating-project).\n",
    "- Create a [Jupyter Notebook](https://www.ibm.com/docs/en/watsonx/saas?topic=editor-creating-managing-notebooks).\n",
    "This step will open a Notebook environment where you can copy the code from this tutorial.  Alternatively, you can download this notebook to your local system and upload it to your watsonx.ai project as an asset.\n",
    "\n",
    "### 2. **Watson Machine Learning (WML) Service**\n",
    "- Create a [WML Service Instance](https://cloud.ibm.com/catalog/services/watson-machine-learning) (Lite Plan recommended).\n",
    "- Generate an [API Key](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-authentication.html).\n",
    "- Associate the WML service to the project that you created in [watsonx.ai](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/assoc-services.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Installation and Imports**\n",
    "Install necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installations\n",
    "!pip install -q git+https://github.com/ibm-granite-community/utils \\\n",
    "    chromadb==0.3.26 \\\n",
    "    sentence-transformers \\\n",
    "    ibm-watsonx-ai \\\n",
    "    ibm_watson_machine_learning \\\n",
    "    PyPDF2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import chromadb\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.foundation_models.embeddings.sentence_transformer_embeddings import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from ibm_watsonx_ai.client import APIClient\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions\n",
    "### Logging Setup\n",
    "Configure logging for monitoring and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credential Setup\n",
    "Please store your WATSONX_URL & WATSONX_APIKEY in a separate .env file in the same level of your directory as this notebook. The folder contains an env_template for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "\n",
    "\n",
    "def get_credentials():\n",
    "    return {\n",
    "        \"url\": get_env_var(\"WATSONX_URL\"),\n",
    "        \"apikey\": get_env_var(\"WATSONX_APIKEY\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Reading\n",
    "Extract text from the given PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(pdf_path):\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Chunking\n",
    "Split text into manageable 512-word chunks for efficient processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=512):\n",
    "    words = text.split()\n",
    "    return [\n",
    "        \" \".join(words[i : i + chunk_size]) for i in range(0, len(words), chunk_size)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Text\n",
    "\n",
    "Generate embeddings for text chunks in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_embeddings(emb, texts, batch_size=10):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        embeddings.extend(emb.embed_documents(texts[i : i + batch_size]))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChromaDB Hydration\n",
    "Populate ChromaDB with text embeddings for efficient querying.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hydrate_chromadb(pdf_path, emb, collection_name=\"pdf_collection\"):\n",
    "    # Read and chunk the PDF content\n",
    "    text = read_pdf(pdf_path)\n",
    "    chunks = chunk_text(text)\n",
    "\n",
    "    # Embed the chunks\n",
    "    try:\n",
    "        embeddings = batch_embeddings(emb, chunks)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error embedding text: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Initialize ChromaDB client\n",
    "    chroma_client = chromadb.Client()\n",
    "\n",
    "    # Clean up existing collection\n",
    "    try:\n",
    "        chroma_client.delete_collection(name=collection_name)\n",
    "        logger.info(f\"Existing collection '{collection_name}' deleted.\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"No existing collection to delete or error: {e}\")\n",
    "\n",
    "    # Create new collection\n",
    "    collection = chroma_client.create_collection(name=collection_name)\n",
    "\n",
    "    # Add the embeddings to the collection\n",
    "    try:\n",
    "        collection.add(\n",
    "            embeddings=embeddings,\n",
    "            documents=chunks,\n",
    "            metadatas=[{\"chunk_index\": i} for i in range(len(chunks))],\n",
    "            ids=[f\"chunk_{i}\" for i in range(len(chunks))],\n",
    "        )\n",
    "        logger.info(\"ChromaDB collection populated successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error populating ChromaDB: {e}\")\n",
    "        return None\n",
    "\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proximity Search \n",
    "Retrieve relevant sections of the contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximity_search(question, collection, emb):\n",
    "    try:\n",
    "        query_vectors = emb.embed_query(question)\n",
    "        query_result = collection.query(\n",
    "            query_embeddings=query_vectors,\n",
    "            n_results=5,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"],\n",
    "        )\n",
    "        documents = list(reversed(query_result[\"documents\"][0]))\n",
    "        return \"\\n\".join(documents)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during proximity search: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup\n",
    "This cell sets up the **Granite-3-8b-instruct** model, to generate detailed responses based on contract analysis. It configures the model with specific parameters (such as token limits and repetition penalties) and uses the previously defined credentials to authenticate. The SentenceTransformerEmbeddings model is also initialized here, enabling the embedding of the contract text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ibm/granite-3-8b-instruct\"\n",
    "parameters = {\n",
    "    \"decoding_method\": \"greedy\",\n",
    "    \"max_new_tokens\": 5000,\n",
    "    \"min_new_tokens\": 0,\n",
    "    \"repetition_penalty\": 1,\n",
    "}\n",
    "project_id = \"c8018aee-3437-4f94-a493-7513583350f3\"\n",
    "\n",
    "model = Model(\n",
    "    model_id=model_id,\n",
    "    params=parameters,\n",
    "    credentials=get_credentials(),\n",
    "    project_id=project_id,\n",
    ")\n",
    "\n",
    "# Initialize Sentence Transformer\n",
    "emb = SentenceTransformerEmbeddings(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate ChromaDB\n",
    "In this step, we specify the contract file using the pdf_path variable. The hydrate_chromadb function is then used to extract the text from the contract, split it into smaller chunks, generate embeddings, and store those embeddings in the ChromaDB database.\n",
    "\n",
    "To analyze a contract of your choice, follow these simple steps:\n",
    "1. **Add your contract file**: Place your contract PDF file into a folder named \"contracts\".\n",
    "2. **Update the file path**: Change the pdf_path variable to point to your contract file inside the \"contracts\" folder. For example, if your file is   named my_contract.pdf, update the path like this:\n",
    "    ```python\n",
    "        pdf_path = './Contracts/my_contract.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./Contracts/Landlord_Filed_Contract.pdf\"\n",
    "\n",
    "chroma_collection = hydrate_chromadb(pdf_path, emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate AI Response\n",
    "\n",
    "Analyze the contract for legal and financial risks using Granite LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis():\n",
    "    question = \"Analyze the contract for legal and financial risks\"\n",
    "    context = proximity_search(question, chroma_collection, emb)\n",
    "\n",
    "    prompt_input = \"\"\"<|start_of_role|>system<|end_of_role|>You are Granite, an AI language model developed by IBM in 2024. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior. You are a AI language model designed to function as a specialized Retrieval Augmented Generation (RAG) assistant. When generating responses, prioritize correctness, i.e., ensure that your response is correct given the context and user query, and that it is grounded in the context. Furthermore, make sure that the response is supported by the given document or context. Always make sure that your response is relevant to the question. If an explanation is needed, first provide the explanation or reasoning, and then give the final answer. Avoid repeating information unless asked.<|end_of_text|>\n",
    "        <|start_of_role|>user<|end_of_role|>Analyze the following contract for legal and financial risks. Present the analysis in a structured format with detailed sections, as described below:\n",
    "\n",
    "        Expected Output Format\n",
    "        1. General Overview\n",
    "        Summarize key contract details, including:\n",
    "\n",
    "        Dates mentioned in the contract\n",
    "        Names of the Parties.\n",
    "        Scope of Work or Agreement.\n",
    "        2. Key Highlights\n",
    "        Highlight important contract terms such as:\n",
    "\n",
    "        Payment Terms.\n",
    "        Intellectual Property Rights.\n",
    "        Termination Provisions.\n",
    "        Dispute Resolution Methods.\n",
    "        3. Detailed Risk Analysis\n",
    "        For each major contract section, identify:\n",
    "\n",
    "        Potential Risks (e.g., vague terms, unfavorable clauses).\n",
    "        Severity of the risks (e.g., Low, Medium, High, Critical).\n",
    "        Mitigation Strategies to address the risks.\n",
    "        4. Recommendations and Actionable Insights\n",
    "        Provide practical recommendations to address the identified risks and improve the contract.\n",
    "\n",
    "        5. Compliance Checklist\n",
    "        List all compliance issues, unaddressed risks, or sections that require revision.\n",
    "\n",
    "        6. Summary of Risks by Severity\n",
    "           Create a **table summarizing risks**, with clear severity classification and corresponding mitigation strategies. The table should follow this format:\n",
    "            | Risk                               | Severity     | Mitigation Strategy                              |\n",
    "            |------------------------------------|--------------|--------------------------------------------------|\n",
    "            | Example: Rent Increases            | High         | Negotiate caps on annual increases.              |\n",
    "\n",
    "        <|end_of_role|>\n",
    "\n",
    "        # Generate AI response with context and user prompt\"\"\"\n",
    "\n",
    "    formatted_prompt = f\"\"\"<|start_of_role|>user<|end_of_role|>Use the following pieces of context to answer the question.\n",
    "\n",
    "    {context}\n",
    "\n",
    "    {prompt_input}<|end_of_role|>\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        generated_response = model.generate_text(\n",
    "            prompt=formatted_prompt, guardrails=False\n",
    "        )\n",
    "        formatted_response = generated_response.replace(\"\\n\", \"\\n\")\n",
    "        print(formatted_response)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating response: {e}\")\n",
    "\n",
    "\n",
    "generate_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "granite-cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
