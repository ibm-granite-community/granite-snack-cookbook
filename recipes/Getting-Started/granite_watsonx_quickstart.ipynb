{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Quickstart: Using IBM Granite 3.3 on watsonx.ai (with LangChain)\n",
    "\n",
    "This notebook is a step-by-step tutorial for running **Granite 3.3** models on **IBM watsonx.ai** from your Jupyter environment. It covers prerequisites, how to get your credentials and project set up in IBM Cloud, local installation, environment configuration, choosing the right model, and a minimal Hello World via both the **ibm-watsonx-ai** SDK and **LangChain**.\n",
    "\n",
    "**What you'll do**\n",
    "1. Complete IBM Cloud prerequisites (account, API key, watsonx.ai project).\n",
    "2. Install the required Python packages.\n",
    "3. Choose a **Granite 3.3** model (e.g., `granite-3-3-8b-instruct`).\n",
    "4. Make a generation request with the **IBM SDK**.\n",
    "5. Make the same request via **LangChain**.\n",
    "\n",
    "> ℹ️ **Granite 3.3** (2B/8B; Base & Instruct) improves reasoning, coding, and instruction following; supports **128K** token context and developer-friendly prompting patterns (e.g., FIM).  \n",
    "> References: [watsonx.ai foundation model catalog](https://www.ibm.com/products/watsonx-ai/foundation-models), [Granite 3.3 docs](https://www.ibm.com/granite/docs/models/granite/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 0) Prerequisites\n",
    "\n",
    "Before running any code here, complete these steps in IBM Cloud:\n",
    "\n",
    "1. **Create / sign in to an IBM Cloud account** and provision **watsonx.ai**.  \n",
    "   - Go to [IBM Cloud](cloud.ibm.com) and sign up or log in with your IBM ID.\n",
    "   - If you’re new, you can start with a Lite plan or apply a promo code for free credits.\n",
    "   - Create a Watsonx.ai service instance from your IBM Cloud dashboard. This provides access to IBM foundation models, including Granite 3.3.\n",
    "   - After login, navigate to the IBM watsonx.ai service from the IBM Cloud Catalog. Go to Catalog → AI & Machine Learning → watsonx.ai.\n",
    "2. **Create a watsonx.ai Project**\n",
    "   - In the watsonx.ai console, click Projects → View all projects → New project.\n",
    "   - Choose:\n",
    "      - Empty project (start from scratch), or\n",
    "      - Sample project (with preloaded assets), or\n",
    "      - Import project (upload a .zip from another environment).\n",
    "   - Name your project (must be unique, 1–255 chars, no %, \\\\, or leading/trailing spaces).\n",
    "   - Storage requirement: Associate an IBM Cloud Object Storage instance (create one if you don’t have it).\n",
    "   - Click Create. Your project now has:\n",
    "      - A unique Project ID (needed for API calls).\n",
    "      - A dedicated storage bucket for assets.\n",
    "   - Note your service **URL** (region endpoint), e.g., `https://us-south.ml.cloud.ibm.com`. \n",
    "3. **Associate Watson Machine Learning Service**\n",
    "   - Open your project -> Click on Manage at the top nav bar -> Services and Integrations.\n",
    "   - Click Associate Service -> choose Watson Machine Learning (WML). Note: You must have Admin role in project.\n",
    "   - If you don’t have a WML instance:\n",
    "      - Go to IBM Cloud Catalog → Watson Machine Learning.\n",
    "      - Create an instance in the same region as your project.\n",
    "      - Once created, link the WML instance to your project.\n",
    "      - This step is required for running foundation models and APIs.\n",
    "4. **Obtain Your Credentials**\n",
    "   - In IBM Cloud, go to Manage → Access (IAM) → [API keys](https://cloud.ibm.com/iam/apikeys).\n",
    "   - Create an API key (or use an existing one).\n",
    "   - Download or copy your key immediately (cannot see again after creation).\n",
    "   - Note:\n",
    "      - API Key → used for authentication.\n",
    "      - Service URL → e.g., https://us-south.ml.cloud.ibm.com.\n",
    "      - Project ID → from your watsonx.ai project details. In watsonx.ai, open left menu > Projects > View all projects. Select your desired project.\n",
    "      - Go to Manage tab > General. Copy Project ID for later.\n",
    "      - You should see Watson Machine Learning listed under Services for your project.\n",
    "      - These three values (API_KEY, URL, PROJECT_ID) are required for SDK and LangChain integration.\n",
    "      - See: [Credentials for programmatic access](https://www.ibm.com/docs/en/watsonx/saas?topic=resources-credentials-programmatic-access). \n",
    "5. Validate  Access\n",
    "   -  Ensure your IBM Cloud user has Editor role for watsonx.ai and WML services.\n",
    "   - If you plan to use APIs directly, confirm you can generate a Bearer token using your API key.\n",
    "6. (Optional) In **Resource hub** or **Prompt Lab**: \n",
    "   - review Granite 3.3 models and copy the exact **`model_id`**. You can also list available models via API (shown later).  \n",
    "   - See: [Get foundation model information / model IDs](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-api-model-ids.html?context=wx&audience=wdp).\n",
    "\n",
    "> You will paste **three values** into this notebook: `WATSONX_URL`, `WATSONX_APIKEY`, and `PROJECT_ID`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1) Choosing a Granite 3.3 model\n",
    "\n",
    "**Granite 3.3 variants:**\n",
    "- **Instruct**: `granite-3-3-2b-instruct`, `granite-3-3-8b-instruct` — best default for apps (chat, Q&A, reasoning, summaries, coding).  \n",
    "- **Base**: `granite-3-3-2b-base`, `granite-3-3-8b-base` — pre-trained backbone; choose if you plan to fine-tune or do advanced prompting.\n",
    "\n",
    "**How to choose**\n",
    "- **2B vs 8B**: 2B is faster/cheaper; **8B** yields stronger reasoning and output quality.  \n",
    "- **Context**: Granite 3.3 supports **up to 128K tokens**, ideal for long docs and RAG pipelines.  \n",
    "- **Features**: Better reasoning/math/coding, function/tool calling support patterns, and **FIM** for code completion flows.  \n",
    "References: [IBM foundation models](https://www.ibm.com/products/watsonx-ai/foundation-models), [Granite 3.3 docs & examples](https://www.ibm.com/granite/docs/models/granite/).\n",
    "\n",
    "> ⚠️ Availability can be **region-specific**; if a model isn’t found, check your region’s catalog or list models via API (Section 4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2) Install packages locally\n",
    "\n",
    "Run the next cell to install the SDKs and helpers:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install ibm-watsonx-ai langchain langchain-ibm python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3) Configure your local environment\n",
    "\n",
    "Set the required settings as environment variables for this session. (For reuse across sessions, see the optional `.env` helper in the next cell.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# --- Paste your values when prompted ---\n",
    "WATSONX_URL = os.environ.get(\"WATSONX_URL\") or input(\"watsonx.ai URL (e.g., https://us-south.ml.cloud.ibm.com): \")\n",
    "WATSONX_APIKEY = os.environ.get(\"WATSONX_APIKEY\") or getpass(\"IBM Cloud API Key: \")\n",
    "PROJECT_ID = os.environ.get(\"PROJECT_ID\") or input(\"watsonx.ai Project ID: \")\n",
    "\n",
    "# Persist in this process\n",
    "os.environ[\"WATSONX_URL\"] = WATSONX_URL\n",
    "os.environ[\"WATSONX_APIKEY\"] = WATSONX_APIKEY\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "\n",
    "print(\"✅ Environment variables set (not saved to disk).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### (Optional) Save a local `.env` for reuse\n",
    "This helper writes your current values into a `.env` file (don’t commit secrets). You can then `source` it or use `python-dotenv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, PurePath\n",
    "\n",
    "env_text = f\"\"\"WATSONX_URL={os.environ['WATSONX_URL']}\n",
    "WATSONX_APIKEY={os.environ['WATSONX_APIKEY']}\n",
    "PROJECT_ID={os.environ['PROJECT_ID']}\n",
    "MODEL_ID=granite-3-3-8b-instruct\n",
    "\"\"\"\n",
    "Path('.env').write_text(env_text)\n",
    "print('Wrote .env (contains secrets)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 4) Hello World with the **ibm-watsonx-ai** SDK\n",
    "\n",
    "A minimal generation call with a Granite 3.3 Instruct model.  \n",
    "Docs: [ibm-watsonx-ai Python library](https://www.ibm.com/docs/en/watsonx/saas?topic=resources-python-library)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "import os\n",
    "\n",
    "MODEL_ID = os.environ.get(\"MODEL_ID\", \"ibm/granite-3-3-8b-instruct\")  # set to 2B if desired\n",
    "\n",
    "params = {\n",
    "    \"decoding_method\": \"sample\",\n",
    "    \"max_new_tokens\": 128,\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "creds = Credentials(url=os.environ['WATSONX_URL'], api_key=os.environ['WATSONX_APIKEY'])\n",
    "model = ModelInference(\n",
    "    model_id=MODEL_ID,\n",
    "    credentials=creds,\n",
    "    project_id=os.environ['PROJECT_ID'],\n",
    "    params=params,\n",
    ")\n",
    "\n",
    "prompt = \"Say hello to the world in one short sentence.\"\n",
    "result = model.generate(prompt)\n",
    "print(result)\n",
    "\n",
    "# Pretty-print primary text if present\n",
    "try:\n",
    "    print(\"\\n--- Generated text ---\\n\")\n",
    "    print(result[\"results\"][0][\"generated_text\"])\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 5) Hello World with **LangChain**\n",
    "\n",
    "LangChain’s `WatsonxLLM` wrapper uses your watsonx **URL**, **project_id**, and **model_id**.  \n",
    "Docs: [LangChain watsonx integration](https://python.langchain.com/docs/integrations/llms/ibm_watsonx/), [langchain-ibm (PyPI)](https://pypi.org/project/langchain-ibm/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ibm import WatsonxLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "\n",
    "parameters = {\n",
    "    \"decoding_method\": \"sample\",\n",
    "    \"max_new_tokens\": 64,\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 1.0,\n",
    "}\n",
    "\n",
    "llm = WatsonxLLM(\n",
    "    model_id=os.environ.get('MODEL_ID', 'ibm/granite-3-3-8b-instruct'),\n",
    "    url=os.environ['WATSONX_URL'],\n",
    "    project_id=os.environ['PROJECT_ID'],\n",
    "    params=parameters,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a friendly assistant. Reply very briefly.\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "print(chain.invoke({\"question\": \"Give me a 5-word greeting.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
