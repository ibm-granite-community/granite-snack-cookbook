{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04c3f983",
   "metadata": {},
   "source": [
    "# AI-Driven Log Triage Tool: Self-Contained Notebook\n",
    "\n",
    "This Jupyter Notebook is a self-contained implementation of an AI-driven log analyzer powered by IBM Granite via Ollama, using LangChain for model interaction. It scans log files from a local ZIP, detects errors, and generates verbose, expert-level recommendations for DevOps engineers debugging pipelines or applications. All code is included, with dependencies installed within the notebook.\n",
    "\n",
    "**Features**:\n",
    "- Processes ZIP files containing `.log` files.\n",
    "- Detects errors using regex (e.g., 'ERROR', 'Exception').\n",
    "- Generates recommendations with IBM Granite via Ollama, using LangChain.\n",
    "- Outputs text or JSON reports.\n",
    "\n",
    "**Sample Data**:\n",
    "- 3 generic `.log` files (`build.log`, `test.log`, `deploy.log`).\n",
    "- Licensed under [CDLA-Permissive-2.0](https://cdla.dev/permissive-2.0/).\n",
    "\n",
    "**Prerequisites**:\n",
    "- **Python**: 3.8+ (tested with 3.13).\n",
    "- **Ollama**: Install from [ollama.com](https://ollama.com/). Run `ollama serve` and pull `granite3.3:8b` (or `llama3` fallback).\n",
    "- **Dependencies**: `requests`, `click`, `langchain`, `langchain-ollama` (installed in this Notebook).\n",
    "\n",
    "**Setup**:\n",
    "To avoid PEP 668 errors, use a virtual environment:\n",
    "```bash\n",
    "cd /Users/userName/Documents/workspace/ai-log-triage\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install --upgrade pip\n",
    "pip install jupyter\n",
    "jupyter notebook ai_log_triage_notebook_langchain.ipynb\n",
    "```\n",
    "\n",
    "**License**:\n",
    "- Code: MIT License.\n",
    "- Sample Data: CDLA-Permissive-2.0.\n",
    "\n",
    "**MIT License**:\n",
    "Copyright (c) 2025 Your Name. Permission is hereby granted to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies, subject to including this notice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e419b46",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies\n",
    "\n",
    "Install required packages within the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52790384",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests>=2.28.0 click>=8.1.0 langchain>=0.2.0 langchain-ollama>=0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44ddcb",
   "metadata": {},
   "source": [
    "## Step 2: Define Core Functions\n",
    "\n",
    "Core logic for log triage, including verbose AI recommendations using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8e2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "import tempfile\n",
    "from typing import List, Dict, Optional\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Initialize Ollama model with LangChain\n",
    "llm = OllamaLLM(model=\"granite3.3:8b\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "# Define prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"file\", \"line_number\", \"message\", \"previous_line\"],\n",
    "    template=\"\"\"\n",
    "You are an advanced AI-powered log analysis expert, designed to diagnose and resolve issues in system logs with precision and insight. Your expertise lies in identifying error patterns, interpreting log context, and providing actionable recommendations to streamline DevOps workflows. Given the following log details from the file '{file}':\n",
    "- Line Number: {line_number}\n",
    "- Error Message: {message}\n",
    "- Previous Line (for context): {previous_line}\n",
    "\n",
    "Perform a thorough analysis of the error, focusing on the log file’s context (e.g., build, test, or deployment logs) and common DevOps scenarios. Provide a detailed recommendation in the following structured format:\n",
    "1. **Problem**: Clearly describe the issue indicated by the error message, including its potential impact on the system or process.\n",
    "2. **Possible Causes**: List 2-3 likely reasons for the error, drawing on common log patterns, system behaviors, or configuration issues.\n",
    "3. **Solution**: Recommend specific, actionable steps to resolve the issue, prioritizing the most likely cause. Include diagnostic commands, configuration checks, or code adjustments as needed. Ensure the steps are practical for a DevOps engineer to implement.\n",
    "\n",
    "Ensure your response is clear, concise, and tailored to the provided log details, avoiding overly generic advice. If the error is ambiguous, suggest diagnostic steps to gather more information.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def extract_zip(zip_path: str, temp_dir: str) -> List[str]:\n",
    "    \"\"\"Extract ZIP file to temporary directory and return list of .log files.\n",
    "\n",
    "    Args:\n",
    "        zip_path (str): Path to the ZIP file.\n",
    "        temp_dir (str): Directory to extract files to.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of paths to extracted .log files.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the ZIP is invalid or contains no .log files.\n",
    "    \"\"\"\n",
    "    log_files = []\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "        for root, _, files in os.walk(temp_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.log'):\n",
    "                    log_files.append(os.path.join(root, file))\n",
    "        if not log_files:\n",
    "            raise ValueError(\"No .log files found in ZIP\")\n",
    "        return log_files\n",
    "    except zipfile.BadZipFile:\n",
    "        raise ValueError(\"Invalid ZIP file\")\n",
    "\n",
    "def scan_logs(log_file: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Scan a log file for errors and return list of issues.\n",
    "\n",
    "    Args:\n",
    "        log_file (str): Path to the log file.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: List of issues with file, line number, message, and previous line.\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    error_patterns = [r'ERROR.*', r'[Ee]xception.*', r'failed with code \\d+']\n",
    "    with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        lines = f.readlines()\n",
    "        for i, line in enumerate(lines, 1):\n",
    "            for pattern in error_patterns:\n",
    "                if re.search(pattern, line):\n",
    "                    previous_line = lines[i-2].strip() if i > 1 else ''\n",
    "                    issues.append({\n",
    "                        'file': os.path.basename(log_file),\n",
    "                        'line_number': str(i),\n",
    "                        'message': line.strip(),\n",
    "                        'previous_line': previous_line\n",
    "                    })\n",
    "                    break\n",
    "    return issues\n",
    "\n",
    "def get_ai_recommendation(issue: Dict[str, str]) -> str:\n",
    "    \"\"\"Generate AI recommendation using IBM Granite via Ollama and LangChain.\n",
    "\n",
    "    Args:\n",
    "        issue (Dict[str, str]): Issue details (file, line_number, message, previous_line).\n",
    "\n",
    "    Returns:\n",
    "        str: AI-generated recommendation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chain = prompt_template | llm\n",
    "        response = chain.invoke({\n",
    "            \"file\": issue['file'],\n",
    "            \"line_number\": issue['line_number'],\n",
    "            \"message\": issue['message'],\n",
    "            \"previous_line\": issue['previous_line'] or 'N/A'\n",
    "        })\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"\"\"\n",
    "1. **Problem**: Pipeline failure detected in {issue['file']} at line {issue['line_number']}: {issue['message']}. This error may halt the process or indicate a critical issue in the system.\n",
    "2. **Possible Causes**:\n",
    "   - Misconfiguration in the pipeline or application settings.\n",
    "   - Insufficient system resources (e.g., memory, disk space).\n",
    "   - A bug or unhandled exception in the application code.\n",
    "3. **Solution**:\n",
    "   - Check configuration files for errors or inconsistencies.\n",
    "   - Verify system resources using commands like `df -h` for disk space or `free -m` for memory.\n",
    "   - Review the application code at the relevant section, focusing on error handling and input validation.\n",
    "   - Enable debug logging to capture additional context and rerun the process.\n",
    "Error details: {str(e)}\n",
    "\"\"\"\n",
    "\n",
    "def generate_report(issues: List[Dict[str, str]]) -> List[Dict]:\n",
    "    \"\"\"Generate report with recommendations for all issues.\n",
    "\n",
    "    Args:\n",
    "        issues (List[Dict[str, str]]): List of issues from scan_logs.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: Report with file, line_number, error, and recommendation.\n",
    "    \"\"\"\n",
    "    report = []\n",
    "    for issue in issues:\n",
    "        recommendation = get_ai_recommendation(issue)\n",
    "        report.append({\n",
    "            'file': issue['file'],\n",
    "            'line_number': issue['line_number'],\n",
    "            'error': issue['message'],\n",
    "            'recommendation': recommendation\n",
    "        })\n",
    "    return report\n",
    "\n",
    "def output_report(report: List[Dict], output_format: str, output_file: Optional[str] = None):\n",
    "    \"\"\"Output report in text or JSON format.\n",
    "\n",
    "    Args:\n",
    "        report (List[Dict]): Report from generate_report.\n",
    "        output_format (str): 'text' or 'json'.\n",
    "        output_file (Optional[str]): File path for JSON output (optional).\n",
    "    \"\"\"\n",
    "    if output_format == 'json':\n",
    "        report_json = json.dumps(report, indent=2)\n",
    "        if output_file:\n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write(report_json)\n",
    "        else:\n",
    "            print(report_json)\n",
    "    else:\n",
    "        for item in report:\n",
    "            print(f\"File: {item['file']}\")\n",
    "            print(f\"Line: {item['line_number']}\")\n",
    "            print(f\"Error: {item['error']}\")\n",
    "            print(f\"Recommendation:\\n{item['recommendation']}\\n\")\n",
    "\n",
    "def generate_sample_data(zip_path: str = 'sample_logs.zip') -> str:\n",
    "    \"\"\"Generate sample log data under CDLA-Permissive-2.0 license.\n",
    "\n",
    "    Args:\n",
    "        zip_path (str): Path to save the ZIP file (default: 'sample_logs.zip').\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the generated ZIP file.\n",
    "    \"\"\"\n",
    "    sample_logs = {\n",
    "        'build.log': [\n",
    "            '[2025-04-23 10:00:01] Starting build process...',\n",
    "            '[2025-04-23 10:00:02] Compiling source code...',\n",
    "            '[2025-04-23 10:00:03] ERROR: Process failed with code 1',\n",
    "            '[2025-04-23 10:00:04] Build aborted.'\n",
    "        ],\n",
    "        'test.log': [\n",
    "            '[2025-04-23 10:01:01] Running test suite...',\n",
    "            '[2025-04-23 10:01:02] Test case 1 passed.',\n",
    "            '[2025-04-23 10:01:03] Exception: Null pointer detected',\n",
    "            '[2025-04-23 10:01:04] Test suite failed.'\n",
    "        ],\n",
    "        'deploy.log': [\n",
    "            '[2025-04-23 10:02:01] Starting deployment...',\n",
    "            '[2025-04-23 10:02:02] Configuring server...',\n",
    "            '[2025-04-23 10:02:03] WARNING: Deployment timeout',\n",
    "            '[2025-04-23 10:02:04] Deployment incomplete.'\n",
    "        ]\n",
    "    }\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        for log_file, lines in sample_logs.items():\n",
    "            with open(os.path.join(temp_dir, log_file), 'w') as f:\n",
    "                f.write('\\n'.join(lines))\n",
    "        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for log_file in sample_logs.keys():\n",
    "                zipf.write(os.path.join(temp_dir, log_file), log_file)\n",
    "    return zip_path\n",
    "\n",
    "print(\"Core functions defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19259040",
   "metadata": {},
   "source": [
    "## Step 3: Define CLI-Like Function\n",
    "\n",
    "This function mimics CLI behavior, allowing analysis of local ZIP files with command-line-style arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db2e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import click\n",
    "\n",
    "def run_triage(zip_path: str, output_format: str = 'text', output_file: Optional[str] = None, generate_sample: bool = False) -> None:\n",
    "    \"\"\"Run the log triage tool with CLI-like arguments.\n",
    "\n",
    "    Args:\n",
    "        zip_path (str): Path to the ZIP file containing logs.\n",
    "        output_format (str): 'text' or 'json' (default: 'text').\n",
    "        output_file (Optional[str]): File path for JSON output (optional).\n",
    "        generate_sample (bool): If True, generate sample log data (default: False).\n",
    "    \"\"\"\n",
    "    if generate_sample:\n",
    "        zip_path = generate_sample_data()\n",
    "        print(f\"Generated sample data at {zip_path}\")\n",
    "\n",
    "    if not os.path.exists(zip_path):\n",
    "        print(f\"Error: {zip_path} does not exist\")\n",
    "        return\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        try:\n",
    "            # Extract ZIP\n",
    "            log_files = extract_zip(zip_path, temp_dir)\n",
    "            print(f\"Found {len(log_files)} .log files\")\n",
    "\n",
    "            # Scan logs\n",
    "            all_issues = []\n",
    "            for log_file in log_files:\n",
    "                issues = scan_logs(log_file)\n",
    "                all_issues.extend(issues)\n",
    "                print(f\"Scanned {log_file}: {len(issues)} issues\")\n",
    "\n",
    "            if not all_issues:\n",
    "                print(\"No issues found in logs\")\n",
    "                return\n",
    "\n",
    "            # Generate report\n",
    "            report = generate_report(all_issues)\n",
    "            print(f\"Generated report for {len(report)} issues\")\n",
    "\n",
    "            # Output report\n",
    "            output_report(report, output_format, output_file)\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {str(e)}\")\n",
    "\n",
    "print(\"CLI-like function defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61d906",
   "metadata": {},
   "source": [
    "## Step 4: Test Sample Data (Text Output)\n",
    "\n",
    "Generate `sample_logs.zip` and analyze it, displaying results in text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7611d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_triage(zip_path='sample_logs.zip', output_format='text', generate_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645eaebd",
   "metadata": {},
   "source": [
    "## Step 5: Test Sample Data (JSON Output)\n",
    "\n",
    "Generate `sample_logs.zip`, analyze it, and save the report as `report.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3462bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_triage(zip_path='sample_logs.zip', output_format='json', output_file='report.json', generate_sample=True)\n",
    "\n",
    "# Display JSON\n",
    "with open('report.json', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869678b",
   "metadata": {},
   "source": [
    "## Step 6: Programmatic Use\n",
    "\n",
    "Use core functions directly to demonstrate modularity with sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = generate_sample_data()\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    log_files = extract_zip(zip_path, temp_dir)\n",
    "    all_issues = []\n",
    "    for log_file in log_files:\n",
    "        issues = scan_logs(log_file)\n",
    "        all_issues.extend(issues)\n",
    "    if all_issues:\n",
    "        report = generate_report(all_issues)\n",
    "        output_report(report, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a6c5cc",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Testing**: Use Steps 4 and 5 to test with sample data, or Step 6 for programmatic use.\n",
    "- **Customization**: Modify the `PromptTemplate` for specific error types or add more sample logs.\n",
    "- **Extend for Your Logs**: Users can leverage this notebook’s functionality (e.g., `extract_zip`, `scan_logs`, `get_ai_recommendation`) to create a tailored log analyzer for your own log files. Replace `sample_logs.zip` with your ZIP file containing logs, adjust regex patterns in `scan_logs` for domain-specific errors, or enhance the `PromptTemplate` to include custom context relevant to your systems.\n",
    "\n",
    "- **Incorporate Troubleshooting Guides**: Feed a troubleshooting guide into the AI by appending its content to the `PromptTemplate` or preprocessing it into the log analysis pipeline. For example, parse a guide’s steps and include them as context in `get_ai_recommendation` to provide more precise, guide-aligned solutions.\n",
    "\n",
    "- **Scalable Approach with Embeddings and Vector Search**: Transform this into a sophisticated, scalable solution using embeddings and vector search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
