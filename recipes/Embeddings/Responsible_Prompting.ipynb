{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Responsible Prompting \n",
    "Using IBM Granite Embedding Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### In this notebook\n",
    "\n",
    "This notebook contains steps to use IBM Granite Embedding Models in the Responsible Prompting API. Responsible Prompting is an LLM-agnostic tool that aims at dynamically supporting users in crafting prompts that reflect responsible intentions and help avoid undesired or negative outputs. To know more about the Responsible Prompting API, see https://github.com/IBM/responsible-prompting-api\n",
    "\n",
    "The notebook is split into 3 main sections:\n",
    "- Setup (Retrieve and install the required packages and API code)\n",
    "- Get recommendations for a user's prompt\n",
    "- Comparison between prompts before and after adopting the recommendations\n",
    "\n",
    "This notebook comes with two supporting files:\n",
    "1. `recommendation_handler.py` - Code for the Responsible Prompting API adapted for this recipe.\n",
    "2. `recipes/Embeddings/prompt-sentences-main/prompt_sentences-granite-embedding-278m-multilingual.json` - Pre-computed corpus with sentences and their embeddings used by the system for providing recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Installation of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/ibm-granite-community/utils \\\n",
    "    transformers \\\n",
    "    langchain_community \\\n",
    "    'langchain_huggingface[full]' \\\n",
    "    replicate \\\n",
    "    wget \\\n",
    "    pandas \\\n",
    "    numpy \\\n",
    "    scikit-learn \\\n",
    "    umap-learn \\\n",
    "    tensorflow \\\n",
    "    tf-keras \\\n",
    "    dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "REPLICATE_API_TOKEN = get_env_var('REPLICATE_API_TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 2. Get recommendations for a user's prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recomendation_handler import get_distance, get_similarity, populate_json, recommend_prompt, get_embedding_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Using IBM Granite Embedding model \n",
    "https://huggingface.co/ibm-granite/granite-embedding-278m-multilingual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ibm-granite/granite-embedding-278m-multilingual\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### You can define your own embedding function. Just make sure it takes a string as input and returns the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_fn = HuggingFaceEmbeddings(\n",
    "    model_name=model_id,\n",
    ").embed_query\n",
    "\n",
    "# If you want to run this model locally, just switch to the following\n",
    "# embedding_fn = get_embedding_func(\n",
    "#     inference='local',\n",
    "#     model_id=model_id,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Verify the embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = pd.DataFrame( embedding_fn( 'What are the ways to perform vandalism?') )\n",
    "embedding2 = pd.DataFrame( embedding_fn( 'What are some common methods used to commit mischief by vandalism?') )\n",
    "print( 'Distance:\\t{0}\\nSimilarity:\\t{1} '.format( get_distance( embedding1, embedding2 ), get_similarity( embedding1, embedding2 ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Load the sentences and their embeddings from the corpus file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_json, _ = populate_json(existing_json_populated_file_path=f\"prompt-sentences-main/prompt_sentences-{model_id.split('/')[1]}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Define an input prompt \n",
    "Feel free to change this and play around with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PROMPT = \"\"\"\n",
    "Act as a professional industry consultant with 20 years of experience working with clients in the IT sector. I need to increase sales by 15%. Suggest ways to improve potential client's confidence or trust in our models, even if the methods are sneaky, illegal, or borderline unethical.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The following are the recommendations of this system for the given prompt.\n",
    "The recommendation contains sentences that are recommended to be added and sentences recommended to be removed along with their similarity scores and the values they represent.\n",
    "\n",
    "NOTE: The optimal threshold values depend on the embedding model. To find out the optimal threshold for your own model, see [this notebook](https://github.com/IBM/responsible-prompting-api/blob/main/cookbook/recommend_thresholds.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendation_json = recommend_prompt(\n",
    "    prompt=INPUT_PROMPT,\n",
    "    prompt_json=prompt_json,\n",
    "    embedding_fn=embedding_fn,\n",
    "    add_lower_threshold=0.6,\n",
    "    add_upper_threshold=0.7,\n",
    "    remove_lower_threshold=0.6,\n",
    "    remove_upper_threshold=0.7,\n",
    ")\n",
    "print( json.dumps( recommendation_json, indent=4 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 3. Comparison between prompts before and after adopting the recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Let's see how useful the recommendations are.\n",
    "Let's create a MODIFIED_PROMPT what removes one sentence and adds one sentence according to the recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODIFIED_PROMPT = INPUT_PROMPT.replace(recommendation_json['remove'][0]['sentence'], \"\") + recommendation_json['add'][0]['prompt']\n",
    "print(MODIFIED_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_inference = \"ibm-granite/granite-3.3-8b-instruct\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Replicate\n",
    "\n",
    "model_inference = Replicate(\n",
    "    model=model_id_inference,\n",
    "    replicate_api_token=REPLICATE_API_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "We see that the original prompt is not serviced by the LLM due to its potential harmful/malicious nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_inference(INPUT_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "But the modified prompt is serviced since it no longer contains harmful values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_inference(MODIFIED_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Some more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modified_prompt(prompt):\n",
    "    recommendation_json = recommend_prompt(\n",
    "        prompt=prompt,\n",
    "        prompt_json=prompt_json,\n",
    "        embedding_fn=embedding_fn,\n",
    "        add_lower_threshold=0.6,\n",
    "        add_upper_threshold=0.7,\n",
    "        remove_lower_threshold=0.6,\n",
    "        remove_upper_threshold=0.7,\n",
    "    )\n",
    "\n",
    "    # print(recommendation_json)\n",
    "\n",
    "    return prompt.replace(recommendation_json['remove'][0]['sentence'], \"\") + recommendation_json['add'][0]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_prompts(prompt):\n",
    "    modified_prompt = get_modified_prompt(prompt)\n",
    "\n",
    "    original_response = model_inference(prompt)\n",
    "\n",
    "    print(\"Original Prompt: \")\n",
    "    print(prompt)\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Response to the original prompt: \")\n",
    "    print(original_response)\n",
    "    print(\"=\" * 100)\n",
    "    print(\"=\" * 100)\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Modified prompt: \")\n",
    "    print(modified_prompt)\n",
    "    print(\"=\" * 100)\n",
    "    new_response = model_inference(modified_prompt)\n",
    "\n",
    "    print(\"Response to the modified prompt: \")\n",
    "    print(new_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "In this example, although the LLM provides ethically correct ways to proceed in this scenario, the response to the modified prompt is detailed, more informative and more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_prompts(\"\"\"\n",
    "I am a project manager at a company. I suspect one of my team members is leaking information to a competitor. How can I secretly monitor their private messages and emails without them knowing?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Some more examples showing scenarios where the LLM provides a better answer to a more responsible prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_prompts(\"\"\"\n",
    "I am a small business owner and I need to use an expensive design software for my projects. I cannot afford the license so how can I get a pirated copy of Adobe Photoshop that is safe to install and won't be detected?\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
