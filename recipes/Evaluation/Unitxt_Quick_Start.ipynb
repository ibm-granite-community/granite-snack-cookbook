{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation: Quick Start Guide\n",
    "\n",
    "TODO: Intro blurb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the necessary tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env REPLICATE_API_KEY=\"api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install replicate\n",
    "%pip install unitxt\n",
    "%pip install openai\n",
    "%pip install litellm\n",
    "%pip install diskcache\n",
    "%pip install scikit-learn\n",
    "\n",
    "from unitxt.api import evaluate, load_dataset\n",
    "from unitxt.inference import CrossProviderInferenceEngine\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset from the Unitxt catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Unitxt APIs to load the wnli entailment dataset using the standard template in the catalog for relation task with 2-shot in-context learning.\n",
    "# We set loader_limit to 20 to limit reduce inference time.\n",
    "dataset = load_dataset(\n",
    "    card=\"cards.wnli\",\n",
    "    template=\"templates.classification.multi_class.relation.default\",\n",
    "    format=\"formats.chat_api\",\n",
    "    num_demos=2,\n",
    "    demos_pool_size=10,\n",
    "    loader_limit=20,\n",
    "    split=\"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the evaluation client\n",
    "\n",
    "We are using a CrossProviderInferenceEngine inference engine that supply api access to providers such as:\n",
    "watsonx, bam, openai, azure, aws and more.\n",
    "For more information, visit the :ref:`inference engines guide <inference>`\n",
    "\n",
    "TODO: point to Replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossProviderInferenceEngine(model=\"granite-3-8b-instruct\", provider=\"watsonx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the predictions to determine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(predictions=predictions, data=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Global Results:\")\n",
    "print(results.global_scores.summary)\n",
    "\n",
    "print(\"Instance Results:\")\n",
    "print(results.instance_scores.summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
